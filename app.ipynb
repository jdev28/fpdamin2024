{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "T-VZQW2unBYN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi Scraping Data\n",
        "def scrape_books():\n",
        "    import requests\n",
        "    from bs4 import BeautifulSoup\n",
        "    import pandas as pd # Import pandas within the function's scope\n",
        "\n",
        "    base_url = \"https://books.toscrape.com/catalogue/\"\n",
        "    start_url = \"https://books.toscrape.com/catalogue/page-1.html\"\n",
        "\n",
        "    books_data = []\n",
        "    max_books = 100\n",
        "\n",
        "    while start_url and len(books_data) < max_books:\n",
        "        response = requests.get(start_url)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        for book in soup.find_all('article', class_='product_pod'):\n",
        "            if len(books_data) >= max_books:\n",
        "                break\n",
        "\n",
        "            title = book.h3.a['title']\n",
        "            price = book.find('p', class_='price_color').text[1:].replace('Â', '').strip()\n",
        "            rating = book.p['class'][1]\n",
        "            availability = book.find('p', class_='instock availability').text.strip()\n",
        "\n",
        "            books_data.append({\n",
        "                'Title': title,\n",
        "                'Price': float(price.replace('£', '')),\n",
        "                'Rating': rating,\n",
        "                'Availability': availability\n",
        "            })\n",
        "\n",
        "        next_page = soup.find('li', class_='next')\n",
        "        if next_page:\n",
        "            next_url = next_page.a['href']\n",
        "            start_url = base_url + next_url\n",
        "        else:\n",
        "            start_url = None\n",
        "\n",
        "    return pd.DataFrame(books_data)"
      ],
      "metadata": {
        "id": "St0NfXxOnFea"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi Preprocessing Data\n",
        "def clean_and_preprocess_data(df):\n",
        "    df.drop(columns=['Availability'], inplace=True, errors='ignore')\n",
        "    df.drop_duplicates(inplace=True)\n",
        "    rating_mapping = {\n",
        "        'One': 1,\n",
        "        'Two': 2,\n",
        "        'Three': 3,\n",
        "        'Four': 4,\n",
        "        'Five': 5\n",
        "    }\n",
        "    df['Rating'] = df['Rating'].map(rating_mapping)\n",
        "    df.dropna(inplace=True)\n",
        "    df['Price'] = pd.to_numeric(df['Price'], errors='coerce')\n",
        "    df.dropna(inplace=True)\n",
        "    return df"
      ],
      "metadata": {
        "id": "hAQgko9mnKH9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi Visualisasi\n",
        "def visualize_data(df):\n",
        "    st.subheader(\"Visualisasi Data\")\n",
        "    st.write(\"Berikut adalah beberapa visualisasi data untuk analisis awal.\")\n",
        "\n",
        "    # Visualisasi Harga Buku\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
        "    sns.histplot(df['Price'], bins=30, kde=True, ax=ax[0])\n",
        "    ax[0].set_title('Distribusi Harga Buku')\n",
        "    sns.boxplot(x=df['Price'], ax=ax[1])\n",
        "    ax[1].set_title('Variasi Harga Buku')\n",
        "    st.pyplot(fig)\n",
        "\n",
        "    # Distribusi Rating\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    sns.countplot(x='Rating', data=df, palette='viridis', ax=ax)\n",
        "    ax.set_title('Distribusi Rating Buku')\n",
        "    st.pyplot(fig)\n",
        "\n",
        "    # Korelasi Harga dan Rating\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    sns.scatterplot(x='Rating', y='Price', data=df, ax=ax)\n",
        "    ax.set_title('Korelasi Harga dan Rating')\n",
        "    st.pyplot(fig)"
      ],
      "metadata": {
        "id": "FL6eMM4unNzt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk Menjalankan Skenario\n",
        "def run_scenario(df):\n",
        "    scenario_option = st.selectbox(\"Pilih Skenario:\", [\n",
        "        \"Skenario 1: Prediksi Harga Buku\",\n",
        "        \"Skenario 2: Prediksi Ketersediaan Stok\",\n",
        "        \"Skenario 3: Segmentasi Buku Berdasarkan Harga dan Rating\",\n",
        "        \"Skenario 4: Prediksi Harga Buku dengan KNN\"\n",
        "    ])\n",
        "\n",
        "    if scenario_option == \"Skenario 1: Prediksi Harga Buku\":\n",
        "        st.subheader(\"Skenario 1: Prediksi Harga Buku berdasarkan Rating\")\n",
        "        st.write(\"**Penjelasan:**\")\n",
        "        st.write(\"Skenario ini bertujuan untuk memprediksi harga buku berdasarkan rating yang diberikan.\")\n",
        "        st.write(\"Model yang digunakan:\")\n",
        "        st.write(\"1. **Linear Regression**: Untuk hubungan linear antara rating dan harga.\")\n",
        "        st.write(\"2. **Decision Tree Regression**: Untuk menangkap pola non-linear.\")\n",
        "\n",
        "        # Splitting the data\n",
        "        X = df[['Rating']]\n",
        "        y = df['Price']\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Train Linear Regression\n",
        "        model_reg = LinearRegression()\n",
        "        model_reg.fit(X_train, y_train)\n",
        "        y_pred_reg = model_reg.predict(X_test)\n",
        "\n",
        "        # Train Decision Tree Regression\n",
        "        model_tree = DecisionTreeRegressor(random_state=42)\n",
        "        model_tree.fit(X_train, y_train)\n",
        "        y_pred_tree = model_tree.predict(X_test)\n",
        "\n",
        "        # Calculate metrics\n",
        "        mse_reg = mean_squared_error(y_test, y_pred_reg)\n",
        "        mse_tree = mean_squared_error(y_test, y_pred_tree)\n",
        "        r2_reg = r2_score(y_test, y_pred_reg)\n",
        "        r2_tree = r2_score(y_test, y_pred_tree)\n",
        "\n",
        "        # Evaluation Metrics\n",
        "        st.write(\"**Hasil:**\")\n",
        "        st.write(\"- **Mean Squared Error (Linear Regression):** {:.2f}\".format(mse_reg))\n",
        "        st.write(\"- **Mean Squared Error (Decision Tree Regression):** {:.2f}\".format(mse_tree))\n",
        "        st.write(\"- **R-squared (Linear Regression):** {:.2f}\".format(r2_reg))\n",
        "        st.write(\"- **R-squared (Decision Tree Regression):** {:.2f}\".format(r2_tree))\n",
        "\n",
        "        # Visualization: MSE and R-squared Comparison\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "        # Visualisasi Perbandingan MSE\n",
        "        mse_scores = [mse_reg, mse_tree]\n",
        "        axes[0].bar(['Linear Regression', 'Decision Tree'], mse_scores, color=['blue', 'orange'])\n",
        "        axes[0].set_title('Perbandingan Mean Squared Error (MSE)')\n",
        "        axes[0].set_ylabel('MSE')\n",
        "        for i, v in enumerate(mse_scores):\n",
        "            axes[0].text(i, v + 0.05, f'{v:.2f}', ha='center')\n",
        "\n",
        "        # Visualisasi Perbandingan R-squared\n",
        "        r2_scores = [r2_reg, r2_tree]\n",
        "        axes[1].bar(['Linear Regression', 'Decision Tree'], r2_scores, color=['blue', 'orange'])\n",
        "        axes[1].set_title('Perbandingan R-squared')\n",
        "        axes[1].set_ylabel('R-squared')\n",
        "        for i, v in enumerate(r2_scores):\n",
        "            axes[1].text(i, v + 0.02, f'{v:.2f}', ha='center')\n",
        "\n",
        "        st.pyplot(fig)\n",
        "\n",
        "        # Determine optimal model\n",
        "        st.write(\"**Model yang Lebih Optimal:**\")\n",
        "        if mse_reg < mse_tree:\n",
        "            st.write(\"- Linear Regression lebih optimal berdasarkan MSE.\")\n",
        "        else:\n",
        "            st.write(\"- Decision Tree Regression lebih optimal berdasarkan MSE.\")\n",
        "\n",
        "        if r2_reg > r2_tree:\n",
        "            st.write(\"- Linear Regression lebih optimal berdasarkan R-squared.\")\n",
        "        else:\n",
        "            st.write(\"- Decision Tree Regression lebih optimal berdasarkan R-squared.\")\n",
        "\n",
        "\n",
        "    elif scenario_option == \"Skenario 2: Prediksi Ketersediaan Stok\":\n",
        "        st.subheader(\"Skenario 2: Prediksi Ketersediaan Stok\")\n",
        "        st.write(\"**Penjelasan:**\")\n",
        "        st.write(\"Skenario ini bertujuan untuk memprediksi apakah suatu buku tersedia ('In stock') atau tidak ('Out of stock') berdasarkan harga dan rating buku.\")\n",
        "        st.write(\"Model yang digunakan:\")\n",
        "        st.write(\"1. **Random Forest Classifier**: Menggunakan ensemble decision trees untuk meningkatkan akurasi.\")\n",
        "        st.write(\"2. **Logistic Regression**: Memprediksi probabilitas ketersediaan stok berdasarkan fitur input.\")\n",
        "\n",
        "        # Preprocessing for Availability\n",
        "        df['Availability'] = df['Price'].apply(lambda x: 'In stock' if x > 50 else 'Out of stock')\n",
        "        X = df[['Price', 'Rating']]\n",
        "        y = df['Availability'].map({'In stock': 1, 'Out of stock': 0})\n",
        "\n",
        "        # Splitting the data\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Train Logistic Regression\n",
        "        model_lr = LogisticRegression()\n",
        "        model_lr.fit(X_train, y_train)\n",
        "        y_pred_lr = model_lr.predict(X_test)\n",
        "        accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
        "        cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
        "\n",
        "        # Train Random Forest Classifier\n",
        "        model_rf = RandomForestClassifier(random_state=42)\n",
        "        model_rf.fit(X_train, y_train)\n",
        "        y_pred_rf = model_rf.predict(X_test)\n",
        "        accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "        cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
        "\n",
        "        # Evaluation Metrics\n",
        "        st.write(\"**Hasil:**\")\n",
        "        st.write(\"- **Akurasi Logistic Regression:** {:.2f}\".format(accuracy_lr))\n",
        "        st.write(\"- **Akurasi Random Forest Classifier:** {:.2f}\".format(accuracy_rf))\n",
        "\n",
        "        # Visualization: Accuracy Comparison\n",
        "        fig, ax = plt.subplots(figsize=(8, 6))\n",
        "        ax.bar(['Logistic Regression', 'Random Forest'], [accuracy_lr, accuracy_rf], color=['blue', 'green'])\n",
        "        ax.set_title('Perbandingan Accuracy')\n",
        "        ax.set_ylabel('Accuracy')\n",
        "        for i, v in enumerate([accuracy_lr, accuracy_rf]):\n",
        "            ax.text(i, v + 0.02, f'{v:.2f}', ha='center')\n",
        "        st.pyplot(fig)\n",
        "\n",
        "        # Visualization: Confusion Matrix Comparison\n",
        "        st.write(\"**Perbandingan Confusion Matrix:**\")\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "        # Logistic Regression Confusion Matrix\n",
        "        sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues', ax=axes[0])\n",
        "        axes[0].set_title(\"Logistic Regression\")\n",
        "        axes[0].set_xlabel(\"Predicted Label\")\n",
        "        axes[0].set_ylabel(\"True Label\")\n",
        "\n",
        "        # Random Forest Confusion Matrix\n",
        "        sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Greens', ax=axes[1])\n",
        "        axes[1].set_title(\"Random Forest Classifier\")\n",
        "        axes[1].set_xlabel(\"Predicted Label\")\n",
        "        axes[1].set_ylabel(\"True Label\")\n",
        "\n",
        "        st.pyplot(fig)\n",
        "\n",
        "\n",
        "    elif scenario_option == \"Skenario 3: Segmentasi Buku Berdasarkan Harga dan Rating\":\n",
        "        st.subheader(\"Skenario 3: Segmentasi Buku Berdasarkan Harga dan Rating\")\n",
        "        st.write(\"**Penjelasan:**\")\n",
        "        st.write(\"Segmentasi buku berdasarkan harga dan rating menggunakan K-Means atau DBSCAN.\")\n",
        "        X_clust = df[['Price', 'Rating']]\n",
        "        model_option = st.selectbox(\"Pilih Model Clustering:\", [\"K-Means\", \"DBSCAN\"])\n",
        "\n",
        "        if model_option == \"K-Means\":\n",
        "            model = KMeans(n_clusters=3, random_state=42)\n",
        "        else:\n",
        "            model = DBSCAN(eps=0.5, min_samples=5)\n",
        "\n",
        "        labels = model.fit_predict(X_clust)\n",
        "        df['Cluster'] = labels\n",
        "\n",
        "        st.write(\"**Hasil:**\")\n",
        "        st.write(\"- Scatter plot menunjukkan distribusi cluster berdasarkan harga dan rating.\")\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(8, 6))\n",
        "        sns.scatterplot(x='Price', y='Rating', hue='Cluster', data=df, palette='viridis', ax=ax)\n",
        "        ax.set_title(f\"Hasil Clustering dengan {model_option}\")\n",
        "        st.pyplot(fig)\n",
        "\n",
        "    elif scenario_option == \"Skenario 4: Prediksi Harga Buku dengan KNN\":\n",
        "        st.subheader(\"Skenario 4: Prediksi Harga Buku dengan KNN\")\n",
        "        st.write(\"**Penjelasan:**\")\n",
        "        st.write(\"Pada skenario ini, kami memprediksi harga buku berdasarkan rating menggunakan algoritma K-Nearest Neighbors (KNN) atau Support Vector Machine (SVM).\")\n",
        "\n",
        "        # Split data\n",
        "        X = df[['Rating']]\n",
        "        y = df['Price']\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Train and predict with KNN\n",
        "        model_knn = KNeighborsRegressor(n_neighbors=5)\n",
        "        model_knn.fit(X_train, y_train)\n",
        "        y_pred_knn = model_knn.predict(X_test)\n",
        "\n",
        "        # Train and predict with SVM\n",
        "        model_svm = SVR(kernel='linear')\n",
        "        model_svm.fit(X_train, y_train)\n",
        "        y_pred_svm = model_svm.predict(X_test)\n",
        "\n",
        "        # Calculate metrics\n",
        "        mse_knn = mean_squared_error(y_test, y_pred_knn)\n",
        "        mse_svm = mean_squared_error(y_test, y_pred_svm)\n",
        "        r2_knn = r2_score(y_test, y_pred_knn)\n",
        "        r2_svm = r2_score(y_test, y_pred_svm)\n",
        "\n",
        "        st.write(\"**Hasil:**\")\n",
        "        st.write(\"- **Mean Squared Error (MSE):** MSE lebih kecil menunjukkan prediksi yang lebih akurat.\")\n",
        "        st.write(\"- **R-squared (R²):** R² mendekati 1 menunjukkan performa model yang lebih baik.\")\n",
        "\n",
        "        # Visualize comparison\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "        # Visualisasi MSE\n",
        "        mse_values = [mse_knn, mse_svm]\n",
        "        axes[0].bar(['KNN', 'SVM'], mse_values, color=['blue', 'green'])\n",
        "        axes[0].set_xlabel('Model')\n",
        "        axes[0].set_ylabel('Mean Squared Error')\n",
        "        axes[0].set_title('Perbandingan Mean Squared Error')\n",
        "\n",
        "        # Visualisasi R2 Score\n",
        "        r2_values = [r2_knn, r2_svm]\n",
        "        axes[1].bar(['KNN', 'SVM'], r2_values, color=['blue', 'green'])\n",
        "        axes[1].set_xlabel('Model')\n",
        "        axes[1].set_ylabel('R2 Score')\n",
        "        axes[1].set_title('Perbandingan R2 Score')\n",
        "\n",
        "        st.pyplot(fig)"
      ],
      "metadata": {
        "id": "strSufaAnVit"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94vxgVGxntta",
        "outputId": "7c341c3b-1023-421c-96ae-ce2e58068b66"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.41.1-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (11.0.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.25.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (1.18.4)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.12.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.41.1-py2.py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.41.1 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi Utama\n",
        "def main():\n",
        "    import streamlit as st\n",
        "    st.title(\"Final Project Data Mining\")\n",
        "    st.sidebar.header(\"Navigasi\")\n",
        "    st.sidebar.write(\"Kelompok: 8\")\n",
        "    st.sidebar.write(\"**Anggota:**\")\n",
        "    st.sidebar.write(\"1. Rahmat Adzani (21082010173)\")\n",
        "    st.sidebar.write(\"2. Nur Muhammad Zam Zami Zen (21082010189)\")\n",
        "    st.sidebar.write(\"3. Jonathan Devrinno (21082010204)\")\n",
        "    menu = st.sidebar.radio(\"Pilih Langkah:\", [\"Scrape Data\", \"Visualisasi\", \"Scenario\", \"Kesimpulan\"])\n",
        "\n",
        "    if menu == \"Scrape Data\":\n",
        "        st.header(\"Scraping Data\")\n",
        "        df = scrape_books()\n",
        "        st.dataframe(df.head())\n",
        "        st.write(\"Contoh data yang berhasil di scrap dalam bentuk tabel\")\n",
        "\n",
        "        def convert_df_to_csv(dataframe):\n",
        "            return dataframe.to_csv(index=False).encode('utf-8')\n",
        "\n",
        "        csv_data = convert_df_to_csv(df)\n",
        "\n",
        "        st.download_button(\n",
        "            label=\"Download CSV\",\n",
        "            data=csv_data,\n",
        "            file_name='scraped_books_data.csv',\n",
        "            mime='text/csv'\n",
        "        )\n",
        "\n",
        "    elif menu == \"Visualisasi\":\n",
        "        st.header(\"Visualisasi Data\")\n",
        "        df = scrape_books()\n",
        "        df = clean_and_preprocess_data(df)\n",
        "        visualize_data(df)\n",
        "\n",
        "    elif menu == \"Scenario\":\n",
        "        st.header(\"Scenario Analisis\")\n",
        "        df = scrape_books()\n",
        "        df = clean_and_preprocess_data(df)\n",
        "        run_scenario(df)\n",
        "\n",
        "    elif menu == \"Kesimpulan\":\n",
        "        st.title(\"Langkah Kesimpulan\")\n",
        "        st.write(\"Berikut adalah kesimpulan dari hasil analisis yang dilakukan pada keempat skenario:\")\n",
        "\n",
        "        # Scenario 1 Summary\n",
        "        st.subheader(\"Skenario 1: Prediksi Harga Buku\")\n",
        "        st.write(\"1. **Linear Regression** menunjukkan performa yang baik untuk hubungan linear antara rating dan harga buku.\")\n",
        "        st.write(\"2. **Decision Tree Regression** memberikan fleksibilitas untuk pola non-linear.\")\n",
        "        st.write(\"- **Perbandingan:** Linear Regression lebih optimal berdasarkan MSE, sedangkan Decision Tree Regression lebih unggul jika melihat nilai R-squared.\")\n",
        "\n",
        "        # Scenario 2 Summary\n",
        "        st.subheader(\"Skenario 2: Prediksi Ketersediaan Stok\")\n",
        "        st.write(\"1. **Logistic Regression** memiliki akurasi yang lebih tinggi pada data ini untuk prediksi ketersediaan stok buku.\")\n",
        "        st.write(\"2. **Random Forest Classifier** memberikan hasil yang konsisten dengan akurasi mendekati Logistic Regression.\")\n",
        "        st.write(\"- **Perbandingan:** Logistic Regression lebih sederhana dan cepat untuk dataset ini, sementara Random Forest lebih robust untuk data yang lebih kompleks.\")\n",
        "\n",
        "        # Scenario 3 Summary\n",
        "        st.subheader(\"Skenario 3: Segmentasi Buku\")\n",
        "        st.write(\"1. **K-Means Clustering** efektif untuk data dengan distribusi teratur.\")\n",
        "        st.write(\"2. **DBSCAN** cocok untuk data dengan pola non-linear atau outliers.\")\n",
        "        st.write(\"- **Perbandingan:** K-Means lebih stabil pada dataset ini karena distribusi data lebih seimbang.\")\n",
        "\n",
        "        # Scenario 4 Summary\n",
        "        st.subheader(\"Skenario 4: Prediksi Harga Buku dengan KNN\")\n",
        "        st.write(\"1. **K-Nearest Neighbors (KNN)** memberikan hasil yang baik untuk pola lokal dengan data yang cukup.\")\n",
        "        st.write(\"2. **Support Vector Machine (SVM)** unggul pada hubungan yang lebih kompleks dengan margin yang lebih optimal.\")\n",
        "        st.write(\"- **Perbandingan:** KNN lebih sederhana untuk dataset ini, sedangkan SVM lebih unggul untuk data dengan pola kompleks.\")\n",
        "\n",
        "        # Visual Conclusion\n",
        "        st.subheader(\"Kesimpulan Akhir\")\n",
        "        st.write(\"\"\"\n",
        "            Dari keempat skenario di atas, setiap model memiliki kelebihan berdasarkan karakteristik data:\n",
        "            - Model Linear Regression dan Logistic Regression bekerja baik untuk dataset sederhana.\n",
        "            - Random Forest dan Decision Tree cocok untuk pola data yang kompleks.\n",
        "            - K-Means unggul pada clustering data teratur, sedangkan DBSCAN menangani pola non-linear dengan baik.\n",
        "            - KNN bekerja pada skenario sederhana, sementara SVM unggul untuk hubungan kompleks.\n",
        "        \"\"\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIDGcWD_nb9q",
        "outputId": "be66d065-1ced-4421-c226-f8ac89eb3484"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-12-20 01:13:50.194 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:50.197 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:50.199 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:50.201 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:50.205 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:50.206 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:50.207 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:50.208 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:50.209 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:50.210 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:50.211 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:50.212 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:50.213 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:50.214 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:50.215 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:50.216 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:50.217 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:50.219 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:50.220 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:50.221 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:50.222 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:50.223 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:50.227 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:50.228 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:50.229 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:50.230 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:50.231 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:50.232 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:50.233 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:50.234 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:50.235 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:50.236 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:51.866 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:51.868 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:51.873 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:51.877 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:51.878 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:51.880 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:51.891 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:51.893 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:51.895 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:51.897 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:51.899 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-12-20 01:13:51.902 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    }
  ]
}
